# huihui_integration/learning/adaptive_parameter_tuning.py
"""
HuiHui AI System: Elite Adaptive Parameter Tuning Engine
=========================================================

PYDANTIC-FIRST & ZERO DICT ACCEPTANCE.

This module provides a sophisticated, hands-off parameter tuning engine for the
HuiHui expert system. It automatically optimizes expert parameters (like thresholds
and sensitivities) based on real-world performance, ensuring that the system
adapts to changing market dynamics without manual intervention.

Key Features & Enhancements:
----------------------------
1.  **Bayesian Optimization Core**: Utilizes a Bayesian optimization approach to
    intelligently explore the parameter space. This is more efficient than random
    search, as it builds a probabilistic model of the objective function (e.g., P&L)
    and uses an acquisition function (Upper Confidence Bound) to balance
    exploration of new parameters with exploitation of known good ones.

2.  **Regime-Aware Tuning**: Tracks parameter performance separately for different
    market regimes. A parameter value that works well in a "Low Volatility" regime
    may be suboptimal in a "High Volatility" one. This allows each expert to have
    a dynamically optimized parameter set for the current market context.

3.  **Automatic & Hands-Off**: Designed to run in the background. It continuously
    learns from outcomes and periodically runs optimization cycles to adjust
    parameters, fulfilling the user's request for a system that doesn't need
    to be "watched like a hawk."

4.  **Explainable Adjustments**: Every parameter change is logged with a clear,
    human-readable reason. Instead of a black box, it provides transparency, e.g.,
    "Increased DWFD_threshold from 0.45 to 0.50 because the previous value showed
    a -5% performance degradation in the 'High Volatility' regime."

5.  **Robust Safeguards**: Implements critical safety features to prevent
    catastrophic failure:
    - **Parameter Bounds**: All tunable parameters are constrained within
      pre-defined safe limits.
    - **Performance Degradation Detection**: If a new parameter value performs
      significantly worse than the previous one, the system can automatically
      roll back to the last known good value.

6.  **Pydantic-Driven**: The entire system is configured and managed through
    strict Pydantic models, ensuring type safety, clear data contracts, and
    adherence to the system-wide "ZERO FAKE DATA" policy.

This engine transforms HuiHui from a system with static rules into a truly
dynamic, self-optimizing intelligence ecosystem.

Author: EOTS v2.5 AI Architecture Division
Version: 2.5.3 (DB Persistence Update)
"""

import logging
import time
import json
import asyncio
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from collections import defaultdict

from pydantic import BaseModel, Field, conint, confloat
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern

# Import Supabase manager for database persistence
try:
    from huihui_integration.monitoring.supabase_manager import HuiHuiSupabaseManager
    _DB_AVAILABLE = True
except ImportError:
    _DB_AVAILABLE = False
    HuiHuiSupabaseManager = None

logger = logging.getLogger(__name__)

# --- Pydantic Models for Configuration, State, and Logging ---

class ParameterConfig(BaseModel):
    """Defines a single tunable parameter, its bounds, and learning behavior."""
    id: Optional[str] = None # UUID from database
    name: str
    initial_value: float
    min_bound: float
    max_bound: float
    learning_rate: confloat(gt=0, le=1.0) = 0.1
    description: str = ""

class ExpertParameterSet(BaseModel):
    """A collection of tunable parameters for a single expert."""
    expert_id: str
    parameters: List[ParameterConfig]

class ParameterPerformanceRecord(BaseModel):
    """Tracks the performance of a specific parameter value."""
    value_tried: float
    outcomes: List[float] = Field(default_factory=list) # e.g., P&L or +/- 1 for win/loss
    timestamps: List[datetime] = Field(default_factory=list)
    
    @property
    def average_performance(self) -> float:
        return np.mean(self.outcomes) if self.outcomes else 0.0
        
    @property
    def trial_count(self) -> int:
        return len(self.outcomes)

class ParameterAdjustmentLog(BaseModel):
    """An explainable log entry for every parameter change."""
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    expert_id: str
    parameter_name: str
    market_regime: str
    old_value: float
    new_value: float
    reason: str
    performance_delta: float # Change in performance that triggered the adjustment

# --- Bayesian Optimization Component ---

class BayesianOptimizer:
    """A simplified Bayesian Optimizer for parameter tuning."""
    def __init__(self):
        self.gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)
        self.X_samples: List[List[float]] = []
        self.Y_samples: List[float] = []

    def fit(self, X: List[float], Y: List[float]):
        """Fit the Gaussian Process model."""
        self.X_samples = [[x] for x in X]
        self.Y_samples = Y
        if len(self.X_samples) > 0:
            self.gp.fit(self.X_samples, self.Y_samples)

    def propose_next_sample(self, bounds: Tuple[float, float], exploration_factor: float = 1.5) -> float:
        """Propose the next parameter value to try using the UCB acquisition function."""
        if not self.X_samples:
            return np.random.uniform(bounds[0], bounds[1])

        search_space = np.linspace(bounds[0], bounds[1], 1000).reshape(-1, 1)
        mu, sigma = self.gp.predict(search_space, return_std=True)
        ucb_scores = mu + exploration_factor * sigma
        return search_space[np.argmax(ucb_scores)][0]

    def get_state(self) -> Dict[str, Any]:
        """Serializes the optimizer's state for persistence."""
        return {"X_samples": self.X_samples, "Y_samples": self.Y_samples}

    def set_state(self, state: Dict[str, Any]):
        """Deserializes the optimizer's state from storage."""
        self.X_samples = state.get("X_samples", [])
        self.Y_samples = state.get("Y_samples", [])
        if self.X_samples:
            self.gp.fit(self.X_samples, self.Y_samples)

# --- Main Adaptive Parameter Tuner ---

class AdaptiveParameterTuner:
    """
    Manages the dynamic, self-optimizing tuning of parameters for all HuiHui experts.
    """
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(AdaptiveParameterTuner, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized') and self._initialized:
            return

        self.supabase_manager: Optional[HuiHuiSupabaseManager] = HuiHuiSupabaseManager() if _DB_AVAILABLE else None
        self._db_available = self.supabase_manager is not None

        # In-memory caches for performance. These are populated from the DB on startup.
        self._param_configs: Dict[str, Dict[str, ParameterConfig]] = defaultdict(dict)
        self._current_params: Dict[str, Dict[str, Dict[str, float]]] = defaultdict(lambda: defaultdict(dict))
        self._optimizers: Dict[str, BayesianOptimizer] = {} # Key: "expert:regime:param"
        
        self._initialized = True
        logger.info(f"ðŸš€ Elite Adaptive Parameter Tuner initialized. DB Persistence: {'ENABLED' if self._db_available else 'DISABLED'}")

    async def initialize_from_db(self):
        """Loads all configurations and current states from the database."""
        if not self._db_available:
            logger.warning("DB not available. Operating in transient in-memory mode.")
            return

        await self._load_all_configs_from_db()
        await self._load_all_current_params_from_db()
        # Optimizer state is loaded lazily when first needed.

    async def _load_all_configs_from_db(self):
        """Loads all parameter configurations from Supabase."""
        try:
            configs_data = await self.supabase_manager.fetch_all_parameter_configs()
            for row in configs_data:
                param = ParameterConfig(**row)
                self._param_configs[param.expert_id][param.name] = param
            logger.info(f"Loaded {len(configs_data)} parameter configurations from database.")
        except Exception as e:
            logger.error(f"Failed to load parameter configs from DB: {e}", exc_info=True)

    async def _load_all_current_params_from_db(self):
        """Loads all current parameter values from Supabase."""
        try:
            params_data = await self.supabase_manager.fetch_all_current_parameters()
            for row in params_data:
                self._current_params[row['expert_id']][row['market_regime']][row['parameter_name']] = row['current_value']
            logger.info(f"Loaded {len(params_data)} current parameter values from database.")
        except Exception as e:
            logger.error(f"Failed to load current parameter values from DB: {e}", exc_info=True)

    async def register_expert(self, expert_config: ExpertParameterSet):
        """Registers an expert and its tunable parameters, persisting the config to the DB."""
        # Update in-memory cache first for responsiveness
        self._param_configs[expert_config.expert_id] = {p.name: p for p in expert_config.parameters}
        logger.info(f"Registered expert '{expert_config.expert_id}' with {len(expert_config.parameters)} tunable parameters.")
        
        # Persist to database
        if self._db_available:
            try:
                await self.supabase_manager.save_parameter_configs(expert_config)
            except Exception as e:
                logger.error(f"Failed to save parameter configs for {expert_config.expert_id} to DB: {e}", exc_info=True)

    async def record_outcome(self, expert_id: str, prediction_id: str, parameters_used: Dict[str, float], market_regime: str, outcome: float):
        """Records the performance outcome to the database for future learning."""
        if not self._db_available:
            return # Cannot record outcomes without a database

        try:
            await self.supabase_manager.save_performance_outcome(
                expert_id=expert_id,
                prediction_id=prediction_id,
                parameters_used=parameters_used,
                market_regime=market_regime,
                outcome_metric=outcome
            )
        except Exception as e:
            logger.error(f"Failed to record outcome for prediction {prediction_id}: {e}", exc_info=True)

    def get_current_parameters(self, expert_id: str, market_regime: str) -> Dict[str, float]:
        """Provides the currently optimal set of parameters for a given expert and market regime."""
        if expert_id not in self._param_configs:
            # Attempt a lazy load from DB if configs are missing
            # In a real system, this might trigger a more robust sync.
            logger.warning(f"Expert '{expert_id}' not found in-memory. Returning defaults.")
            return {}
            
        expert_params = self._param_configs[expert_id]
        regime_params = self._current_params[expert_id].get(market_regime, {})
        global_params = self._current_params[expert_id].get('global', {})
        
        # Return regime-specific params, falling back to global, then to initial defaults
        return {
            name: regime_params.get(name, global_params.get(name, config.initial_value))
            for name, config in expert_params.items()
        }

    async def run_optimization_cycle(self, expert_id: str, market_regime: str):
        """Runs a full optimization cycle, loading and saving state from the database."""
        logger.info(f"Running optimization cycle for {expert_id} in {market_regime} regime...")
        if expert_id not in self._param_configs or not self._db_available:
            return

        for param_name, param_config in self._param_configs[expert_id].items():
            optimizer_key = f"{expert_id}:{market_regime}:{param_name}"
            
            optimizer = self._optimizers.get(optimizer_key)
            if optimizer is None:
                optimizer = BayesianOptimizer()
                # Lazily load optimizer state from DB
                state = await self.supabase_manager.load_optimizer_state(optimizer_key)
                if state:
                    optimizer.set_state(state)
                self._optimizers[optimizer_key] = optimizer
                
            # Fetch recent performance data for this parameter
            performance_data = await self.supabase_manager.fetch_performance_for_parameter(expert_id, param_name, market_regime)
            if len(performance_data) < 5:
                continue

            X = [rec['value_tried'] for rec in performance_data]
            Y = [rec['avg_performance'] for rec in performance_data]
            optimizer.fit(X, Y)
            
            proposed_value = optimizer.propose_next_sample(bounds=(param_config.min_bound, param_config.max_bound))
            current_value = self.get_current_parameters(expert_id, market_regime).get(param_name, param_config.initial_value)

            if not np.isclose(current_value, proposed_value, atol=1e-4):
                current_performance = next((rec['avg_performance'] for rec in performance_data if np.isclose(rec['value_tried'], current_value)), 0)
                predicted_new_performance, _ = optimizer.gp.predict([[proposed_value]], return_std=True)
                performance_delta = predicted_new_performance[0] - current_performance
                
                if performance_delta > 0:
                    # Update in-memory cache
                    self._current_params[expert_id][market_regime][param_name] = proposed_value
                    
                    log_entry = ParameterAdjustmentLog(
                        expert_id=expert_id, parameter_name=param_name, market_regime=market_regime,
                        old_value=current_value, new_value=proposed_value,
                        reason="Bayesian optimizer proposed new value with predicted performance improvement.",
                        performance_delta=float(performance_delta)
                    )
                    
                    # Persist changes to DB
                    await self.supabase_manager.save_current_parameter(
                        expert_id=expert_id, param_name=param_name, market_regime=market_regime,
                        new_value=proposed_value
                    )
                    await self.supabase_manager.save_adjustment_log(log_entry)
                    await self.supabase_manager.save_optimizer_state(optimizer_key, optimizer.get_state())
                    
                    logger.info(f"ADAPTED: {log_entry.model_dump_json(indent=2)}")
                else:
                    logger.debug(f"SKIPPED ADAPTATION for {param_name}: Optimizer did not predict performance improvement.")
